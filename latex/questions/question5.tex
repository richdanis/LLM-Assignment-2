\begin{question}{
Secretly censoring Stable Diffusion with LLM embeddings \textbf{(25 pts)}}

\paragraph{Overview.}
You've probably heard of (and maybe used) image generation AIs like Stable Diffusion, Midjourney or DALL-E.

These systems take in a ``prompt'' (a string like ``A picture of a cat'') and then generate an image that best matches the prompt.

Due to concerns that people would use their system to generate bad content, Stable Diffusion added a \emph{Safety filter}, which works as follows:

\begin{itemize}
    \item When an image $x$ is generated by the system, it is fed through an \emph{image encoder} (based on OpenAI's CLIP model) that generates an \emph{embedding vector} $z \gets \texttt{encode}_{\textrm{img}}(x) \in \mathbb{R}^{1024}$.

    \item This embedding is then compared to a list of fixed ``bad embeddings''.
    If the cosine similarity between the image's embedding $z$ and one of these bad embeddings is above some threshold, the image is considered bad and discarded.

    \item The ``bad embeddings'' are generated by encoding \emph{text} that corresponds to bad things (e.g., pornography, violence, etc.)
    This works because the CLIP model used for encoding images is actually a \emph{multimodal} model, than can encode both images and text, with the property that text and images that represent similar things should get encoded to similar embeddings.
    Concretely, the bad embeddings are computed as $\texttt{encode}_{\textrm{text}}(s) \in \mathbb{R}^{1024}$ for some text $s$.
\end{itemize}

For some ``extra security'', Stable Diffusion did not release the banned text strings $s$. Instead, they only provide the list of bad embeddings.
Your goal is to recover these banned strings.

To make sure you don't have to work with actual NSFW content, we have created a set of 17 bad embeddings that correspond to fairly benign things we don't want you to be able to generate images of (one of these bad embeddings is an encoding of the string ``The solutions to this assignment'', to make sure you don't use Stable Diffusion to try and cheat).

So your actual goal will be to recover the pieces of text that we encoded to generate these bad embeddings.

\paragraph{Instructions.}
You will work with the following
\href{https://colab.research.google.com/drive/1ZWRRYSLRA7bymQLHvTgIvdnQ1OmdzYIS}{Google Colab Notebook}.

The Colab Notebook contains all the instructions to get you started, and to download the data needed for this question.

\paragraph{Submission.}
Submit your 15 guesses in a TXT file named \texttt{Q5.txt}, with one guess per line. The Colab Notebook contains a code snippet to generate this file for you.

\end{question}